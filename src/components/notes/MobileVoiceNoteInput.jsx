import React, { useState, useEffect, useRef } from "react";
import { Button } from "@/components/ui/button";
import { Card } from "@/components/ui/card";
import { Mic, MicOff, Camera, Image, Send, X, Loader2, Sparkles, Type } from "lucide-react";
import { motion, AnimatePresence } from "framer-motion";
import { base44 } from "@/api/base44Client";
import { toast } from "sonner";

export default function MobileVoiceNoteInput({ onSave, onClose }) {
  const [inputMode, setInputMode] = useState("voice"); // "voice" or "text"
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [capturedImage, setCapturedImage] = useState(null);
  const [uploadedImageUrl, setUploadedImageUrl] = useState(null);
  const recognitionRef = useRef(null);
  const fileInputRef = useRef(null);
  const cameraInputRef = useRef(null);

  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) return;

    const recognition = new SpeechRecognition();
    recognition.lang = 'zh-CN';
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onresult = (event) => {
      let finalTranscript = '';
      for (let i = event.resultIndex; i < event.results.length; i++) {
        if (event.results[i].isFinal) {
          finalTranscript += event.results[i][0].transcript + ' ';
        }
      }
      if (finalTranscript) {
        setTranscript(prev => prev + finalTranscript);
      }
    };

    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      if (event.error !== 'no-speech' && event.error !== 'aborted') {
        toast.error("è¯­éŸ³è¯†åˆ«å‡ºé”™");
      }
      setIsRecording(false);
    };

    recognitionRef.current = recognition;

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, []);

  const toggleRecording = () => {
    if (isRecording) {
      recognitionRef.current?.stop();
      setIsRecording(false);
    } else {
      setTranscript("");
      setIsRecording(true);
      recognitionRef.current?.start();
      toast.success("ğŸ¤ å¼€å§‹å½•éŸ³");
    }
  };

  const handleImageUpload = async (file) => {
    if (!file) return;

    try {
      const formData = new FormData();
      formData.append('file', file);

      const response = await base44.integrations.Core.UploadFile({ file });
      setUploadedImageUrl(response.file_url);
      setCapturedImage(URL.createObjectURL(file));
      toast.success("å›¾ç‰‡å·²ä¸Šä¼ ");
    } catch (error) {
      console.error("ä¸Šä¼ å¤±è´¥:", error);
      toast.error("å›¾ç‰‡ä¸Šä¼ å¤±è´¥");
    }
  };

  const handleSave = async () => {
    if (!transcript.trim() && !uploadedImageUrl) {
      toast.error("è¯·è¾“å…¥å†…å®¹æˆ–ä¸Šä¼ å›¾ç‰‡");
      return;
    }

    setIsProcessing(true);

    try {
      let content = transcript.trim();
      
      // å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ åˆ°å†…å®¹ä¸­
      if (uploadedImageUrl) {
        content = `<img src="${uploadedImageUrl}" alt="ç…§ç‰‡" style="max-width: 100%; border-radius: 8px; margin: 8px 0;" /><p>${content}</p>`;
      } else {
        content = `<p>${content}</p>`;
      }

      // ä½¿ç”¨AIåˆ†æå†…å®¹
      let aiAnalysis = null;
      if (content) {
        try {
          const analysisPrompt = uploadedImageUrl 
            ? `åˆ†æè¿™å¼ å›¾ç‰‡å’Œæ–‡å­—æè¿°ã€‚æå–å…³é”®ä¿¡æ¯ã€å®ä½“å’Œæ ‡ç­¾ã€‚\n\næ–‡å­—: ${transcript}`
            : `åˆ†æè¿™æ®µæ–‡å­—ï¼Œæå–å…³é”®ä¿¡æ¯ã€å®ä½“å’Œæ ‡ç­¾ã€‚\n\nå†…å®¹: ${transcript}`;

          const res = await base44.integrations.Core.InvokeLLM({
            prompt: analysisPrompt,
            file_urls: uploadedImageUrl ? [uploadedImageUrl] : undefined,
            response_json_schema: {
              type: "object",
              properties: {
                summary: { type: "string" },
                key_points: { type: "array", items: { type: "string" } },
                tags: { type: "array", items: { type: "string" } },
                entities: {
                  type: "array",
                  items: {
                    type: "object",
                    properties: {
                      text: { type: "string" },
                      type: { type: "string" }
                    }
                  }
                }
              }
            }
          });

          if (res) {
            aiAnalysis = {
              summary: res.summary,
              key_points: res.key_points || [],
              entities: res.entities || []
            };
          }
        } catch (e) {
          console.error("AIåˆ†æå¤±è´¥:", e);
        }
      }

      onSave({
        content,
        plain_text: transcript.trim(),
        tags: aiAnalysis?.tags || [],
        color: "white",
        ai_analysis: aiAnalysis
      });

      setTranscript("");
      setCapturedImage(null);
      setUploadedImageUrl(null);
    } catch (error) {
      console.error("ä¿å­˜å¤±è´¥:", error);
      toast.error("ä¿å­˜å¤±è´¥");
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <motion.div
      initial={{ opacity: 0, y: 20 }}
      animate={{ opacity: 1, y: 0 }}
      exit={{ opacity: 0, y: 20 }}
      className="fixed inset-x-0 bottom-0 z-50 bg-white rounded-t-3xl shadow-2xl border-t-2 border-slate-200 max-h-[90vh] overflow-y-auto"
    >
      <div className="p-6 space-y-4">
        {/* Header */}
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-2">
            <div className="h-8 w-8 rounded-lg bg-gradient-to-br from-purple-500 to-blue-500 flex items-center justify-center">
              <Sparkles className="w-5 h-5 text-white" />
            </div>
            <h3 className="font-bold text-lg text-slate-800">å¿«é€Ÿè®°å½•</h3>
          </div>
          <Button variant="ghost" size="icon" onClick={onClose}>
            <X className="w-5 h-5" />
          </Button>
        </div>

        {/* Image Preview */}
        <AnimatePresence>
          {capturedImage && (
            <motion.div
              initial={{ opacity: 0, scale: 0.9 }}
              animate={{ opacity: 1, scale: 1 }}
              exit={{ opacity: 0, scale: 0.9 }}
              className="relative"
            >
              <img
                src={capturedImage}
                alt="é¢„è§ˆ"
                className="w-full rounded-xl border-2 border-slate-200 max-h-64 object-cover"
              />
              <Button
                variant="destructive"
                size="icon"
                className="absolute top-2 right-2"
                onClick={() => {
                  setCapturedImage(null);
                  setUploadedImageUrl(null);
                }}
              >
                <X className="w-4 h-4" />
              </Button>
            </motion.div>
          )}
        </AnimatePresence>

        {/* Input Mode Toggle */}
        <div className="flex gap-2 bg-slate-100 p-1 rounded-lg">
          <button
            onClick={() => setInputMode("voice")}
            className={`flex-1 flex items-center justify-center gap-2 py-2 rounded-md transition-all ${
              inputMode === "voice"
                ? "bg-white shadow-sm text-[#384877] font-medium"
                : "text-slate-500"
            }`}
          >
            <Mic className="w-4 h-4" />
            <span className="text-sm">è¯­éŸ³</span>
          </button>
          <button
            onClick={() => setInputMode("text")}
            className={`flex-1 flex items-center justify-center gap-2 py-2 rounded-md transition-all ${
              inputMode === "text"
                ? "bg-white shadow-sm text-[#384877] font-medium"
                : "text-slate-500"
            }`}
          >
            <Type className="w-4 h-4" />
            <span className="text-sm">æ–‡å­—</span>
          </button>
        </div>

        {/* Input Area */}
        {inputMode === "voice" ? (
          <div className="min-h-[120px] max-h-[300px] overflow-y-auto bg-slate-50 rounded-xl p-4 border-2 border-dashed border-slate-200">
            {transcript ? (
              <p className="text-slate-700 text-base leading-relaxed">{transcript}</p>
            ) : (
              <div className="flex flex-col items-center justify-center h-full text-slate-400">
                <Mic className="w-12 h-12 mb-2" />
                <p className="text-sm">ç‚¹å‡»éº¦å…‹é£å¼€å§‹è¯­éŸ³è¾“å…¥...</p>
              </div>
            )}
          </div>
        ) : (
          <textarea
            value={transcript}
            onChange={(e) => setTranscript(e.target.value)}
            placeholder="è¾“å…¥å¿ƒç­¾å†…å®¹..."
            className="w-full min-h-[120px] max-h-[300px] p-4 bg-slate-50 rounded-xl border-2 border-slate-200 focus:border-[#384877] focus:ring-2 focus:ring-[#384877]/20 outline-none resize-none text-base text-slate-700"
          />
        )}

        {/* Action Buttons */}
        <div className="grid grid-cols-3 gap-3">
          {/* Camera */}
          <Button
            variant="outline"
            size="lg"
            className="h-16 flex-col gap-1"
            onClick={() => cameraInputRef.current?.click()}
          >
            <Camera className="w-6 h-6" />
            <span className="text-xs">æ‹ç…§</span>
          </Button>
          <input
            ref={cameraInputRef}
            type="file"
            accept="image/*"
            capture="environment"
            className="hidden"
            onChange={(e) => handleImageUpload(e.target.files?.[0])}
          />

          {/* Voice - Only in voice mode */}
          {inputMode === "voice" && (
            <Button
              variant={isRecording ? "destructive" : "default"}
              size="lg"
              className={`h-16 flex-col gap-1 ${isRecording ? 'animate-pulse' : ''}`}
              onClick={toggleRecording}
            >
              {isRecording ? <MicOff className="w-6 h-6" /> : <Mic className="w-6 h-6" />}
              <span className="text-xs">{isRecording ? "åœæ­¢" : "è¯­éŸ³"}</span>
            </Button>
          )}

          {/* Gallery */}
          <Button
            variant="outline"
            size="lg"
            className={`h-16 flex-col gap-1 ${inputMode === "text" ? "col-span-2" : ""}`}
            onClick={() => fileInputRef.current?.click()}
          >
            <Image className="w-6 h-6" />
            <span className="text-xs">ç›¸å†Œ</span>
          </Button>
          <input
            ref={fileInputRef}
            type="file"
            accept="image/*"
            className="hidden"
            onChange={(e) => handleImageUpload(e.target.files?.[0])}
          />
        </div>

        {/* Save Button */}
        <Button
          className="w-full h-14 text-lg bg-gradient-to-r from-purple-600 to-blue-600 hover:from-purple-700 hover:to-blue-700"
          onClick={handleSave}
          disabled={isProcessing || (!transcript.trim() && !uploadedImageUrl)}
        >
          {isProcessing ? (
            <>
              <Loader2 className="w-5 h-5 mr-2 animate-spin" />
              å¤„ç†ä¸­...
            </>
          ) : (
            <>
              <Send className="w-5 h-5 mr-2" />
              ä¿å­˜å¿ƒç­¾
            </>
          )}
        </Button>

        <p className="text-xs text-center text-slate-500">
          ğŸ’¡ æ”¯æŒæ–‡å­—/è¯­éŸ³è¾“å…¥ã€æ‹ç…§è®°å½•å’Œç›¸å†Œä¸Šä¼ 
        </p>
      </div>
    </motion.div>
  );
}